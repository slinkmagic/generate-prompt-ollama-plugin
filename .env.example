# Ollama API Configuration Template
# Copy this file to .env and update with your actual values
# DO NOT commit .env file to version control

# Ollama API Endpoint
OLLAMA_API_URL=http://localhost:11434

# Optional: Ollama API Token (if authentication is enabled)
# OLLAMA_API_TOKEN=your_token_here

# Optional: Default model for prompt enhancement
OLLAMA_DEFAULT_MODEL=llama2

# Optional: Request timeout in seconds
OLLAMA_TIMEOUT=30

# Optional: Enable debug logging (true/false)
DEBUG_MODE=false

# Optional: Custom prompt templates directory
# CUSTOM_PROMPTS_DIR=./prompts

# Optional: Maximum retry attempts for API calls
MAX_RETRIES=3